{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow-datasets --quiet","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:04:23.184506Z","iopub.execute_input":"2024-09-23T20:04:23.184959Z","iopub.status.idle":"2024-09-23T20:04:37.379020Z","shell.execute_reply.started":"2024-09-23T20:04:23.184921Z","shell.execute_reply":"2024-09-23T20:04:37.377757Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:04:37.381530Z","iopub.execute_input":"2024-09-23T20:04:37.382183Z","iopub.status.idle":"2024-09-23T20:04:50.287631Z","shell.execute_reply.started":"2024-09-23T20:04:37.382132Z","shell.execute_reply":"2024-09-23T20:04:50.286815Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"(train_ds, validation_ds), ds_info = tfds.load(\n    'cats_vs_dogs',\n    split=['train[:80%]', 'train[80%:]'],\n    as_supervised= True,\n    with_info= True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:04:50.288728Z","iopub.execute_input":"2024-09-23T20:04:50.289223Z","iopub.status.idle":"2024-09-23T20:06:06.074857Z","shell.execute_reply.started":"2024-09-23T20:04:50.289191Z","shell.execute_reply":"2024-09-23T20:06:06.073848Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7bf12ba9014b76bfa80c766e0aa255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4e7e83fd4f74f24baf99827d35d1974"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...:   0%|          | 0/23262 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nWarning: unknown JFIF revision number 0.00\nCorrupt JPEG data: 1403 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/cats_vs_dogs/incomplete.G6M5X3_4.0.1/cats_vs_dogs-train.tfrecord*...:   0%…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# PRE-PROCESSING THE IMAGE\ndef preprocess(image, label):\n    image = tf.image.resize(image, [64, 64]) # resizing the images\n    image = tf.cast(image, tf.float32)/255.0 # normalize pixel values, everything is between zero and one\n    return image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:06:06.077168Z","iopub.execute_input":"2024-09-23T20:06:06.077558Z","iopub.status.idle":"2024-09-23T20:06:06.083529Z","shell.execute_reply.started":"2024-09-23T20:06:06.077521Z","shell.execute_reply":"2024-09-23T20:06:06.082372Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def augument(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.5)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:06:06.085089Z","iopub.execute_input":"2024-09-23T20:06:06.085397Z","iopub.status.idle":"2024-09-23T20:06:06.095702Z","shell.execute_reply.started":"2024-09-23T20:06:06.085365Z","shell.execute_reply":"2024-09-23T20:06:06.094551Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.map(preprocess).map(augument).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE) #TRAIN DATASET\nvalidation_ds = validation_ds.map(preprocess).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE) # VALIDATION DATASET","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:06:06.097113Z","iopub.execute_input":"2024-09-23T20:06:06.098061Z","iopub.status.idle":"2024-09-23T20:06:06.267559Z","shell.execute_reply.started":"2024-09-23T20:06:06.098003Z","shell.execute_reply":"2024-09-23T20:06:06.266732Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# BUILDING CNN MODEL\nmodel = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)), # 32 filters of size 3 X 3\n    MaxPooling2D(2,2),\n    Conv2D(64, (3,3), activation='relu'), # 64 filters of size 3 X 3\n    MaxPooling2D(2,2),\n    Flatten(), # flatten everything\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid') # Binary classification, cat or dog\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:06:06.268570Z","iopub.execute_input":"2024-09-23T20:06:06.268846Z","iopub.status.idle":"2024-09-23T20:06:06.351422Z","shell.execute_reply.started":"2024-09-23T20:06:06.268816Z","shell.execute_reply":"2024-09-23T20:06:06.350478Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"# COMPILING THE MODEL\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n# TRAINING THE MODEL\nhistory = model.fit(train_ds, validation_data=validation_ds, epochs=10)\n# EVALUATE THE MODEL\nval_loss, val_accuracy = model.evaluate(validation_ds)\nprint(f\"validation accuracy: {val_accuracy*100:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:06:06.352701Z","iopub.execute_input":"2024-09-23T20:06:06.353088Z","iopub.status.idle":"2024-09-23T20:08:36.576813Z","shell.execute_reply.started":"2024-09-23T20:06:06.353045Z","shell.execute_reply":"2024-09-23T20:08:36.575862Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727121967.724895     127 service.cc:145] XLA service 0x7fc100008dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727121967.724961     127 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1727121967.724966     127 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 14/582\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.4639 - loss: 0.7879","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727121970.358862     127 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.5571 - loss: 0.6811 - val_accuracy: 0.6457 - val_loss: 0.6231\nEpoch 2/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.6713 - loss: 0.5990 - val_accuracy: 0.6948 - val_loss: 0.5742\nEpoch 3/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.7045 - loss: 0.5665 - val_accuracy: 0.7270 - val_loss: 0.5515\nEpoch 4/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.7285 - loss: 0.5379 - val_accuracy: 0.7360 - val_loss: 0.5355\nEpoch 5/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7440 - loss: 0.5153 - val_accuracy: 0.7483 - val_loss: 0.5141\nEpoch 6/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.7586 - loss: 0.4927 - val_accuracy: 0.7537 - val_loss: 0.5044\nEpoch 7/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.7742 - loss: 0.4751 - val_accuracy: 0.7650 - val_loss: 0.4890\nEpoch 8/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.7855 - loss: 0.4576 - val_accuracy: 0.7666 - val_loss: 0.4860\nEpoch 9/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.7967 - loss: 0.4356 - val_accuracy: 0.7794 - val_loss: 0.4689\nEpoch 10/10\n\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8045 - loss: 0.4238 - val_accuracy: 0.7777 - val_loss: 0.4725\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7738 - loss: 0.4789\nvalidation accuracy: 77.77\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}